{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SLCFLAB/Fintech2024-1/blob/main/DL_day10/10_2_Wasserstein_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wasserstein Generative Adversarial Networks\n",
        "\n",
        "Reference: https://github.com/eriklindernoren/PyTorch-GAN/tree/master\n",
        "\n"
      ],
      "metadata": {
        "id": "COa_RjRmitgU"
      },
      "id": "COa_RjRmitgU"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7ecb91bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ecb91bf",
        "outputId": "af5d2c2f-16c9-4ee5-d83c-f5979e9ce83e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(n_epochs=200, batch_size=64, lr=0.0005, b1=0.5, b2=0.999, n_cpu=8, latent_dim=100, img_size=28, channels=1, n_critic=5, clip_value=0.01, sample_interval=400)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import sys\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.autograd as autograd\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0005, help=\"adam: learning rate\")\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\n",
        "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
        "parser.add_argument(\"--n_critic\", type=int, default=5, help=\"number of training steps for discriminator per iter\")\n",
        "parser.add_argument(\"--clip_value\", type=float, default=0.01, help=\"lower and upper clip value for disc. weights\")\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval betwen image samples\")\n",
        "opt = parser.parse_args(args=[])\n",
        "print(opt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "047c3632",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "047c3632",
        "outputId": "162cfcdc-c6d0-4da2-e554-b07f9ccb8175"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False\n",
        "cuda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "abeec002",
      "metadata": {
        "id": "abeec002"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        def block(in_feat, out_feat, normalize=True):\n",
        "            layers = [nn.Linear(in_feat, out_feat)]\n",
        "            if normalize:\n",
        "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "            return layers\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *block(opt.latent_dim, 128, normalize=False),\n",
        "            *block(128, 256),\n",
        "            *block(256, 512),\n",
        "            *block(512, 1024),\n",
        "            nn.Linear(1024, int(np.prod(img_shape))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        img = self.model(z)\n",
        "        img = img.view(img.shape[0], *img_shape)\n",
        "        return img\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(int(np.prod(img_shape)), 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Linear(256, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        img_flat = img.view(img.shape[0], -1)\n",
        "        validity = self.model(img_flat)\n",
        "        return validity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "42f31c5d",
      "metadata": {
        "id": "42f31c5d"
      },
      "outputs": [],
      "source": [
        "k = 2\n",
        "p = 6\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4ea89592",
      "metadata": {
        "id": "4ea89592"
      },
      "outputs": [],
      "source": [
        "# Configure data loader\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "83bcc087",
      "metadata": {
        "scrolled": false,
        "id": "83bcc087"
      },
      "outputs": [],
      "source": [
        "# Optimizers\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------\n",
        "#  Training\n",
        "# ----------\n",
        "\n",
        "batches_done = 0\n",
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor), requires_grad=True)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        fake_imgs = generator(z)\n",
        "\n",
        "        # Real images\n",
        "        real_validity = discriminator(real_imgs)\n",
        "        # Fake images\n",
        "        fake_validity = discriminator(fake_imgs)\n",
        "\n",
        "        # Compute W-div gradient penalty\n",
        "        real_grad_out = Variable(Tensor(real_imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        real_grad = autograd.grad(\n",
        "            real_validity, real_imgs, real_grad_out, create_graph=True, retain_graph=True, only_inputs=True\n",
        "        )[0]\n",
        "        real_grad_norm = real_grad.view(real_grad.size(0), -1).pow(2).sum(1) ** (p / 2)\n",
        "\n",
        "        fake_grad_out = Variable(Tensor(fake_imgs.size(0), 1).fill_(1.0), requires_grad=False)\n",
        "        fake_grad = autograd.grad(\n",
        "            fake_validity, fake_imgs, fake_grad_out, create_graph=True, retain_graph=True, only_inputs=True\n",
        "        )[0]\n",
        "        fake_grad_norm = fake_grad.view(fake_grad.size(0), -1).pow(2).sum(1) ** (p / 2)\n",
        "\n",
        "        div_gp = torch.mean(real_grad_norm + fake_grad_norm) * k / 2\n",
        "\n",
        "        # Adversarial loss\n",
        "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + div_gp\n",
        "\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Train the generator every n_critic steps\n",
        "        if i % opt.n_critic == 0:\n",
        "\n",
        "            # -----------------\n",
        "            #  Train Generator\n",
        "            # -----------------\n",
        "\n",
        "            # Generate a batch of images\n",
        "            fake_imgs = generator(z)\n",
        "            # Loss measures generator's ability to fool the discriminator\n",
        "            # Train on fake images\n",
        "            fake_validity = discriminator(fake_imgs)\n",
        "            g_loss = -torch.mean(fake_validity)\n",
        "\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "            batches_done += opt.n_critic\n",
        "\n",
        "            if i%600==0:\n",
        "                print(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "                % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "                )\n",
        "                images = fake_imgs.data.detach().cpu()\n",
        "                images = images * 0.5 + 0.5  # Revert the normalization to visualize the images properly\n",
        "\n",
        "                # Create a figure to display the images in an 8x8 grid\n",
        "                fig, axes = plt.subplots(nrows=8, ncols=8, figsize=(10, 10))\n",
        "                plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "\n",
        "                # Plot each image in the 8x8 grid\n",
        "                for i, ax in enumerate(axes.flat):\n",
        "                    ax.imshow(images[i].squeeze(), cmap='gray')\n",
        "                    ax.set_xticks([])\n",
        "                    ax.set_yticks([])\n",
        "                plt.show()"
      ],
      "metadata": {
        "id": "-7pRl3A6jH-y"
      },
      "id": "-7pRl3A6jH-y",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}